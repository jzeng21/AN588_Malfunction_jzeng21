---
title: "jzeng21_OriginalHomeworkCode_04"
format: html
editor: visual
---

## Question 1

```{r}
Z.prop.test <- function(p1,n1, p2 = null, n2= null,p0,alternative = "two-sided", conf.level= 0.95) {
  # Check if sample 1 meets normal approximation conditions (n*p > 5 and n*(1-p) > 5)  
  if(n1 * p1 <= 5 || n1 *(1-p1) <= 5){ 
    warning("sample 1 does not meet conditions (n∗p>5
 and n∗(1−p)>5")}

#If either p2 or n2 is NULL, perform a one-sample Z-test
  if (is.null(p2) || is.null(n2)){ 
    se <- sqrt(p0 * (1 - p0) / n1) #here I am doing z denominator and doing the calculation first then assigning it to se so that when I do call it in z I can just do (p1 - p0)/se just more simplified version basically.
    z <- (p1 - p0) / se
    ci <- p1 + c(-1, 1) * qnorm((1 + conf.level) / 2) * se  # instead of writing basically the same code for CI lower and CI upper where the only difference is the sign change. You can actually use a vector c(-1,1) here the multiplication is applied to the vector where it will perform p1 - Z * se then perform p1 + Z * se
    }
   
  else {
    if (n2 * p2 <= 5 || n2 *(1-p2) <= 5){
    warning("sample 2 does not meet conditions (n∗p>5
 and n∗(1−p)>5")
  }
  # Compute pooled proportion
   pooled_p <- (p1 * n1 + p2 * n2) / (n1 + n2)
    se <- sqrt(pooled_p * (1 - pooled_p) * (1 / n1 + 1 / n2))
    z <- (p1 - p2) / se
    ci <- (p1 - p2) + c(-1, 1) * qnorm(1 - (1 - conf.level) / 2) * se
  }
  
  # p-value calculation based on alternative hypothesis 
  p_value <- switch(
    alternative,
    "two.sided" = 2 * (1 - pnorm(abs(z))),
    "less" = pnorm(z),
    "greater" = 1 - pnorm(z),
    stop("Invalid alternative hypothesis. Use 'two.sided', 'less', or 'greater'.")
  )
  
  # # Return a list with test statistics and results
  list(
    Z = z,
    P = p_value,
    CI = ci
  )
}

```

## Question 2

```{r}
library(ggplot2)
library(dplyr)

k_data <- read.csv("C:\\Users\\jzeng21\\Desktop\\AN588\\AN588_Malfunction_jzeng21\\KamilarAndCooperData.csv")
head(k_data)

# Fit a linear model predicting MaxLongevity from Brain Size
model1 <- lm(MaxLongevity_m ~ Brain_Size_Species_Mean, data = k_data)


# Add log-transformed variables for both longevity and brain size
k_data <- k_data %>%
  mutate(log_Longevity = log(MaxLongevity_m),
         log_BrainSize = log(Brain_Size_Species_Mean))

model2 <- lm(log_Longevity ~ log_BrainSize, data = k_data)

# View model summaries including coefficients and statistics
summary(model1)
summary(model2)

# Compute 90% confidence intervals for model coefficients
confint(model1, level = 0.90)
confint(model2, level = 0.90)

# Extract slope (β₁) and intercept (β₀)
beta0_1 <- coef(model1)[1]
beta1_1 <- coef(model1)[2]

# Scatterplot with regression line
p1 <- ggplot(k_data, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  geom_text(x = max(k_data$Brain_Size_Species_Mean) * 0.7, 
            y = max(k_data$MaxLongevity_m) * 0.8, 
            label = paste0("Longevity = ", round(beta0_1, 2), " + ", round(beta1_1, 2), " * Brain Size"),
            color = "black", size = 5) +
  labs(title = "Scatterplot of Longevity vs Brain Size",
       x = "Brain Size (grams)", y = "Longevity (months)") +
  theme_minimal()

print(p1)
```

```{r}

# Extract intercept (β₀) and slope (β₁) for the log-transformed model
beta0_2 <- coef(model2)[1]
beta1_2 <- coef(model2)[2]

# Create a scatterplot for log-transformed variables with a regression line
p2 <- ggplot(k_data, aes(x = log_BrainSize, y = log_Longevity)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  geom_text(x = max(k_data$log_BrainSize) * 0.7, 
            y = max(k_data$log_Longevity) * 0.8, 
            label = paste0("log(Longevity) = ", round(beta0_2, 2), " + ", round(beta1_2, 2), " * log(Brain Size)"),
            color = "black", size = 5) +
  labs(title = "Scatterplot of log(Longevity) vs log(Brain Size)",
       x = "log(Brain Size)", y = "log(Longevity)") +
  theme_minimal()

print(p2)


```

```{r}
# Ensure k_data has no missing values
k_data <- na.omit(k_data) #here I used na.omit to remove any na or non integer values in the data set. 


# Generate a sequence of brain sizes from min to max (100 evenly spaced points)
new_data <- data.frame(
  Brain_Size_Species_Mean = seq(
    min(k_data$Brain_Size_Species_Mean, na.rm = TRUE),
    max(k_data$Brain_Size_Species_Mean, na.rm = TRUE),
    length.out = 100
  )
)

# Predict longevity using Model 1 and compute 90% prediction intervals (PI)
pred <- predict(model1, newdata = new_data, interval = "predict", level = 0.90)
# Compute 90% confidence intervals (CI) for the mean predicted values
conf <- predict(model1, newdata = new_data, interval = "confidence", level = 0.90)

# Merge predictions with new_data
new_data$fit <- pred[, "fit"]
new_data$pi_lower <- pred[, "lwr"]
new_data$pi_upper <- pred[, "upr"]
new_data$ci_lower <- conf[, "lwr"]
new_data$ci_upper <- conf[, "upr"]

# Plot with confidence and prediction intervals
library(ggplot2)

# Add MaxLongevity_m to new_data (use predicted fit as proxy)
new_data$MaxLongevity_m <- new_data$fit  # Assign fit as a proxy

# Plot with CI and PI bands
p3 <- ggplot(k_data, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m)) +
  geom_point() +
  geom_line(data = new_data, aes(x = Brain_Size_Species_Mean, y = fit), color = "blue") +
  geom_ribbon(data = new_data, aes(x = Brain_Size_Species_Mean, ymin = ci_lower, ymax = ci_upper), fill = "blue", alpha = 0.3) +
  geom_ribbon(data = new_data, aes(x = Brain_Size_Species_Mean, ymin = pi_lower, ymax = pi_upper), fill = "red", alpha = 0.2) +
  labs(
    title = "Longevity vs Brain Size with CI and PI",
    x = "Brain Size (grams)",
    y = "Longevity (months)"
  ) +
  theme_minimal() #to make minimal look

print(p3)





```

```{r}
# Create new data point
new_species <- data.frame(Brain_Size_Species_Mean = 800)

# Predict Longevity
predict(model1, new_species, interval = "predict", level = 0.90)

```

```{r}
# Here I want to plot visually see variance in the plots. It will plot 4 graphs per model 
plot(model1)
plot(model2)

```

Since 800g is within the range of observed brain sizes, we can reasonably trust the prediction. However, if it were outside the observed range, extrapolation could be unreliable.

```{r}
# Compare R² values to assess which model fits better.
# Typically, the log-log model shows a stronger linear relationship in biological data.
summary(model1)$r.squared
summary(model2)$r.squared
```

## Conclusion

The log-log model 2 is better as there is a more variance in the outcome. Furthermore, based on the R² values and the nature of biological scaling, the log-log model provides a better fit for the data. It captures the nonlinear relationship between brain size and longevity more effectively.
